{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directories\n",
    "Path(\"../data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../results/plots\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"../results/models\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Modeling imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (classification_report, \n",
    "                            ConfusionMatrixDisplay, \n",
    "                            roc_auc_score,\n",
    "                            accuracy_score)\n",
    "\n",
    "# Algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                             AdaBoostClassifier,\n",
    "                             GradientBoostingClassifier)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --------------------------\n",
    "# Data Loading & Cleaning\n",
    "# --------------------------\n",
    "df = pd.read_csv('../data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "# Data cleaning\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(df['TotalCharges'].median())\n",
    "df = df.drop('customerID', axis=1)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# --------------------------\n",
    "# Feature Engineering\n",
    "# --------------------------\n",
    "df['tenure_group'] = pd.cut(\n",
    "    df['tenure'],\n",
    "    bins=[0, 6, 12, 24, 72],\n",
    "    labels=['0-6 Months', '7-12 Months', '13-24 Months', '25-72 Months']\n",
    ")\n",
    "df['high_charge_short_tenure'] = (\n",
    "    (df['MonthlyCharges'] > 75) & (df['tenure'] < 6)\n",
    ").astype(int)\n",
    "\n",
    "# --------------------------\n",
    "# Feature Validation\n",
    "# --------------------------\n",
    "print(\"\\n=== Feature Validation ===\")\n",
    "print(\"Tenure Group Distribution (Key Segments):\")\n",
    "print(df['tenure_group'].value_counts(normalize=True).loc[['0-6 Months', '25-72 Months']])\n",
    "\n",
    "print(\"\\nHigh Charge + Short Tenure:\")\n",
    "print(f\"{df['high_charge_short_tenure'].mean() * 100:.1f}% of customers\")\n",
    "print(\"Churn Rates:\")\n",
    "print(df.groupby('high_charge_short_tenure')['Churn'].mean().apply(lambda x: f\"{x:.1%}\"))\n",
    "\n",
    "# Save processed data\n",
    "df.to_csv('../data/processed/cleaned_churn_data.csv', index=False)\n",
    "\n",
    "# --------------------------\n",
    "# Visualizations\n",
    "# --------------------------\n",
    "# Churn distribution\n",
    "plt.figure(figsize=(6,6))\n",
    "df['Churn'].value_counts().plot.pie(\n",
    "    autopct='%1.1f%%', \n",
    "    labels=['No Churn', 'Churn'],\n",
    "    colors=['#66b3ff','#ff9999'],\n",
    "    explode=[0.1, 0]\n",
    ")\n",
    "plt.title('Churn Distribution')\n",
    "plt.savefig('../results/plots/churn_distribution.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Tenure vs Charges Analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Scatter plot\n",
    "sns.scatterplot(\n",
    "    data=df, x='tenure', y='MonthlyCharges', hue='Churn',\n",
    "    palette={0: 'blue', 1: 'red'}, alpha=0.7, ax=ax1\n",
    ")\n",
    "ax1.set_title('Tenure vs Monthly Charges by Churn Status')\n",
    "ax1.set_xlabel('Tenure (Months)')\n",
    "ax1.set_ylabel('Monthly Charges ($)')\n",
    "\n",
    "# Histogram\n",
    "sns.histplot(\n",
    "    data=df, x='tenure', hue='Churn', multiple='dodge',\n",
    "    bins=30, palette={0: 'blue', 1: 'red'}, kde=True,\n",
    "    common_norm=False, ax=ax2\n",
    ")\n",
    "ax2.set_title('Tenure Distribution by Churn Status')\n",
    "\n",
    "plt.savefig('../results/plots/tenure_analysis.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Payment method distribution - Horizontal Bar Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "payment_counts = df['PaymentMethod'].value_counts()\n",
    "\n",
    "# Create ordered bar plot with percentages and proper hue handling\n",
    "ax = sns.barplot(\n",
    "    x=payment_counts.values,\n",
    "    y=payment_counts.index,\n",
    "    hue=payment_counts.index,  # Assign y variable to hue\n",
    "    palette='coolwarm',\n",
    "    order=payment_counts.index,\n",
    "    legend=False  # Disable redundant legend\n",
    ")\n",
    "\n",
    "# Add percentage labels\n",
    "for i, count in enumerate(payment_counts):\n",
    "    percentage = (count / len(df)) * 100\n",
    "    ax.text(\n",
    "        x=count + 50,\n",
    "        y=i,\n",
    "        s=f'{percentage:.1f}%', \n",
    "        va='center',\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "plt.title('Payment Method Distribution', fontweight='bold')\n",
    "plt.xlabel('Number of Customers')\n",
    "plt.ylabel('')\n",
    "plt.xlim(0, payment_counts.max() + 250)\n",
    "plt.savefig('../results/plots/payment_methods.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Contract analysis\n",
    "plt.figure(figsize=(8,5))\n",
    "pd.crosstab(df['Contract'], df['Churn'], normalize='index').plot(\n",
    "    kind='bar', stacked=True, cmap='coolwarm'\n",
    ")\n",
    "plt.title('Churn Rate by Contract Type')\n",
    "plt.ylabel('Proportion')\n",
    "plt.savefig('../results/plots/contract_churn.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Correlation analysis\n",
    "\n",
    "# Create encoded copy for correlation analysis\n",
    "encoded_df = df.copy()\n",
    "# Encode ALL categorical features (both object and category dtypes)\n",
    "for col in encoded_df.select_dtypes(include=['object', 'category']).columns:\n",
    "    encoded_df[col] = LabelEncoder().fit_transform(encoded_df[col])\n",
    "\n",
    "# Compute correlations\n",
    "corr_matrix = encoded_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(\n",
    "    corr_matrix[['Churn']]\n",
    "    .sort_values(by='Churn', ascending=False)\n",
    "    .head(15),\n",
    "    annot=True, \n",
    "    cmap='coolwarm', \n",
    "    vmin=-1, \n",
    "    vmax=1,\n",
    "    fmt=\".2f\"\n",
    ")\n",
    "plt.title('Top 15 Features Correlated with Churn')\n",
    "plt.savefig('../results/plots/heatmap_top_correlations.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# Data Preprocessing Pipeline\n",
    "\n",
    "# %%\n",
    "# Identify feature types\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OneHotEncoder(drop='first'), cat_cols)\n",
    "    ])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    stratify=y,\n",
    "    random_state=9\n",
    ")\n",
    "\n",
    "# Apply preprocessing\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Get feature names\n",
    "cat_encoder = preprocessor.named_transformers_['cat']\n",
    "cat_features = cat_encoder.get_feature_names_out(cat_cols)\n",
    "all_features = num_cols + list(cat_features)\n",
    "\n",
    "# ## 5. Model Training & Evaluation\n",
    "def train_evaluate_model(model, model_name):\n",
    "    \"\"\"Train and evaluate a model with standardized output\"\"\"\n",
    "    model.fit(X_train_processed, y_train)\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_proba = model.predict_proba(X_test_processed)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f2 = fbeta_score(y_test, y_pred, beta=2, average='binary')\n",
    "    roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
    "    \n",
    "    # Print comprehensive report\n",
    "    print(f\"\\n{'='*40}\\n{model_name}\\n{'='*40}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F2-Score: {f2:.4f}\")\n",
    "    if not np.isnan(roc_auc):\n",
    "        print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    disp = ConfusionMatrixDisplay.from_estimator(\n",
    "        model, X_test_processed, y_test,\n",
    "        cmap=plt.cm.Blues, display_labels=['No Churn', 'Churn']\n",
    "    )\n",
    "    disp.ax_.set_title(f'{model_name} Confusion Matrix')\n",
    "    plt.savefig(f'../results/plots/{model_name}_cm.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Feature importance\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        plt.figure(figsize=(10,6))\n",
    "        importances = pd.Series(model.feature_importances_, index=all_features)\n",
    "        importances.nlargest(15).plot(kind='barh')\n",
    "        plt.title(f'{model_name} - Top 15 Features')\n",
    "        plt.savefig(f'../results/plots/{model_name}_importance.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    return model, f2\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=25, weights='distance'),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=9\n",
    "    ),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        eval_metric='logloss',\n",
    "        scale_pos_weight=scale_pos_weight,  # Use dynamic calculation\n",
    "        max_depth=3,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.7\n",
    ")\n",
    "}\n",
    "\n",
    "# Train and evaluate all models\n",
    "trained_models = {}\n",
    "metrics = []  # <-- ADD METRICS COLLECTION\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Changed to capture both model and f2_score\n",
    "    trained_model, f2 = train_evaluate_model(model, name)  # <-- UNPACK TUPLE\n",
    "    trained_models[name] = trained_model\n",
    "    \n",
    "    # Save model\n",
    "    pd.to_pickle(trained_model, f'../results/models/{name.replace(\" \", \"_\")}.pkl')\n",
    "    \n",
    "    # Store metrics (ADD THIS BLOCK)\n",
    "    metrics.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, trained_model.predict(X_test_processed)),\n",
    "        'F2-Score': f2,\n",
    "        'AUC-ROC': roc_auc_score(y_test, trained_model.predict_proba(X_test_processed)[:,1]) \n",
    "                   if hasattr(trained_model, \"predict_proba\") else np.nan\n",
    "    })\n",
    "    print(f\"Saved {name} model | F2: {f2:.4f}\\n\")\n",
    "\n",
    "# Generate metrics summary\n",
    "metrics = []\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test_processed)\n",
    "    y_proba = model.predict_proba(X_test_processed)[:,1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    metrics.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': round(accuracy_score(y_test, y_pred), 4),\n",
    "        'AUC-ROC': round(roc_auc_score(y_test, y_proba), 4) if y_proba is not None else np.nan,\n",
    "        'F1-Score': round(f1_score(y_test, y_pred), 4)\n",
    "    })\n",
    "\n",
    "# Create and display metrics\n",
    "metrics_df = pd.DataFrame(metrics).sort_values('AUC-ROC', ascending=False)\n",
    "print(\"\\nFinal Model Comparison:\")\n",
    "display(metrics_df)\n",
    "\n",
    "# Save metrics to proper directory\n",
    "metrics_df.to_csv('../results/model_metrics.csv', index=False)  # Changed path\n",
    "\n",
    "# Load model and validate prediction\n",
    "xgb_model = pd.read_pickle('../results/models/XGBoost.pkl')\n",
    "\n",
    "# Convert to DataFrame if using numpy arrays\n",
    "sample = pd.DataFrame(X_test_processed[0:1], columns=all_features)  # Add feature names\n",
    "print(\"\\nExample Prediction:\")\n",
    "try:\n",
    "    print(f\"Predicted: {xgb_model.predict(sample)[0]} | Actual: {y_test.values[0]}\")\n",
    "except NotFittedError:\n",
    "    print(\"Model not properly trained!\")  # .values for numpy array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
